{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM with _goalReduced_\n",
    "## Characteristics\n",
    "1. **Network type**: BiLSTM cells with Attention System<br><br>\n",
    "2. **goalReduced**: the goal of this network is predict **one** of the goal letter<br>\n",
    "    2.1 You must train 4 of those networks, one for each goal's letter<br>\n",
    "    2.2 The network that predict position *N* of the goal take in input *N-1* goal's letters<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## 1. Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘tmp’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-903a89659db2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrnn_cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatic_bidirectional_rnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import data\n",
    "from tensorflow.nn import rnn_cell\n",
    "from tensorflow.nn import static_bidirectional_rnn\n",
    "import multiprocessing\n",
    "import random as rnd\n",
    "import logging\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "tf.logging.info('version:{}'.format(tf.__version__))\n",
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "random_int = rnd.randint(0,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "## 2. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General params\n",
    "NETWORK_TYPE, GOAL_TYPE = 'BiLSTM_AttentionSystem', 'goalReduced'\n",
    "LOGGING_TO_FILE = True\n",
    "\n",
    "# Debug params\n",
    "DEBUG_HOOK = False\n",
    "\n",
    "\n",
    "# Input params\n",
    "\n",
    "CSV_PATH_TRAIN = \"../database/dbML/knuthFast/knuthFast_2019-07-30_0.9_75844_train.csv\"\n",
    "CSV_PATH_EVAL = \"../database/dbML/knuthFast/knuthFast_2019-07-30_0.9_8516_eval.csv\"\n",
    "\n",
    "\n",
    "# Goal position\n",
    "GOAL_POS = 0 #[0-3]\n",
    "\n",
    "\n",
    "# Model dir\n",
    "MODEL_DIR_PATH = \"model_dir_{}_{}\".format(random_int, GOAL_POS)\n",
    "\n",
    "\n",
    "# Train params\n",
    "LEN_TRAIN_DB = 75844\n",
    "EPOCHS = 10\n",
    "ALPHA = 0.001\n",
    "\n",
    "\n",
    "# Network\n",
    "FW_FORGET_BIAS = 1\n",
    "BW_FORGET_BIAS = 1\n",
    "LSTM_SIZE = 256\n",
    "ATTENTION_SIZE = 256\n",
    "MAXOUT_SIZE = 256\n",
    "DROP_REPRESENTATION = 0.3 \n",
    "\n",
    "L2_ACTIVATED = True\n",
    "L2_SCALE = 0.001\n",
    "\n",
    "\n",
    "# Input \n",
    "BATCH_TRAIN = 4\n",
    "MULTI_THREADING = True\n",
    "\n",
    "# Eval\n",
    "BATCH_EVAL = 4\n",
    "SHUFFLE_EVAL = True\n",
    "EVAL_STEPS = None\n",
    "NUM_EVALS = EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Epochs to steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 10 epochs are equivalent to 189610 steps\n",
      "[INFO] Eval will be executed each 18961 steps for a total of 10 times\n"
     ]
    }
   ],
   "source": [
    "STEPS = int(EPOCHS * (LEN_TRAIN_DB / BATCH_TRAIN))\n",
    "SAVE_CHECKPOINTS_STEPS = int(STEPS / NUM_EVALS) # Do eval each N steps (and save the model)\n",
    "\n",
    "print('[INFO] {} epochs are equivalent to {} steps'.format(EPOCHS, STEPS))\n",
    "print('[INFO] Eval will be executed each {} steps for a total of {} times'.format(SAVE_CHECKPOINTS_STEPS, NUM_EVALS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Persistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What save in model.info\n",
    "model_params = {}\n",
    "model_params['_NETWORK_TYPE'] = NETWORK_TYPE\n",
    "model_params['CSV_PATH_TRAIN'] = CSV_PATH_TRAIN\n",
    "model_params['CSV_PATH_EVAL'] = CSV_PATH_EVAL\n",
    "model_params['MODEL_DIR_PATH'] = MODEL_DIR_PATH\n",
    "model_params['EPOCHS'] = EPOCHS\n",
    "model_params['ALPHA'] = ALPHA\n",
    "model_params['FW_FORGET_BIAS'] = FW_FORGET_BIAS\n",
    "model_params['BW_FORGET_BIAS'] = BW_FORGET_BIAS\n",
    "model_params['LSTM_SIZE'] = LSTM_SIZE\n",
    "model_params['NUM_EVALS'] = NUM_EVALS\n",
    "model_params['BATCH_TRAIN'] = BATCH_TRAIN\n",
    "model_params['BATCH_EVAL'] = BATCH_EVAL\n",
    "model_params['SHUFFLE_EVAL'] = SHUFFLE_EVAL\n",
    "model_params['EVAL_STEPS'] = EVAL_STEPS\n",
    "model_params['MULTI_THREADING'] = MULTI_THREADING\n",
    "model_params['INPUT_ENCODING'] = 'Peg: Hot encoding, Tips: One Hot Encoding'\n",
    "model_params['GOAL'] = GOAL_TYPE\n",
    "model_params['ATTENTION_SIZE'] = ATTENTION_SIZE\n",
    "model_params['MAXOUT_SIZE'] = MAXOUT_SIZE\n",
    "model_params['DROP_REPRESENTATION']= DROP_REPRESENTATION\n",
    "model_params['GOAL_POS'] = GOAL_POS\n",
    "model_params['loss_fn'] = \"mean_pairwise_squared_error\"\n",
    "if L2_ACTIVATED: model_params['L2_SCALE'] = L2_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOGGING_TO_FILE:\n",
    "    tf_log = logging.getLogger('tensorflow')\n",
    "    for el in tf_log.handlers:\n",
    "        tf_log.removeHandler(el)\n",
    "    fh = logging.FileHandler('tf.log')\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    tf_log.addHandler(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "## 4. Estimator components\n",
    "### 4.1 Input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_NAME = ['Guess 1', 'Guess 2', 'Guess 3', 'Guess 4', 'Guess 5',\n",
    "          'Guess 6', 'Guess 7', 'Guess 8', 'Guess 9', 'Guess 10']\n",
    "\n",
    "TARGET_NAME = 'PASSWORD'\n",
    "\n",
    "HEADER = FEATURES_NAME + [TARGET_NAME]\n",
    "\n",
    "HEADER_DEFAULTS = [['<pad>'], ['<pad>'],['<pad>'],['<pad>'],['<pad>'],['<pad>'],\n",
    "                  ['<pad>'],['<pad>'],['<pad>'],['<pad>'],['<pad>']]\n",
    "\n",
    "def input_fn_builder(files_name_pattern, mode, skip_header_lines=0, num_epochs=1, batch_size=32):   \n",
    "    '''\n",
    "    Input function builder, the input_fn returnet could be used\n",
    "    in order to feed an tf.estimator.\n",
    "    \n",
    "    # Params\n",
    "        mode = {\"train\", \"eval\"}\n",
    "    '''    \n",
    "    \n",
    "    # utils\n",
    "    def parse_csv_row(csv_row):\n",
    "        columns = tf.decode_csv(csv_row, record_defaults=HEADER_DEFAULTS, field_delim=',')\n",
    "        features = dict(zip(HEADER, columns))    \n",
    "        target = features[TARGET_NAME]\n",
    "        return features, target\n",
    "\n",
    "    # input function definition\n",
    "    def input_fn_def(files_name_pattern, mode, skip_header_lines, num_epochs, batch_size):\n",
    "        shuffle = True if mode == tf.estimator.ModeKeys.TRAIN else False\n",
    "        num_threads = multiprocessing.cpu_count() if MULTI_THREADING else 1\n",
    "        buffer_size = 2 * batch_size + 1\n",
    "        file_names = tf.matching_files(files_name_pattern) # <matching_files> accept wildcard\n",
    "        dataset = data.TextLineDataset(filenames=file_names)\n",
    "        dataset = dataset.skip(skip_header_lines)\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size)\n",
    "        dataset = dataset.map(lambda csv_row: parse_csv_row(csv_row), \n",
    "                              num_parallel_calls=num_threads)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.repeat(num_epochs)\n",
    "        dataset = dataset.prefetch(buffer_size)\n",
    "        return dataset\n",
    "    \n",
    "    # function builder\n",
    "    if mode == 'train':\n",
    "        mode_key = tf.estimator.ModeKeys.TRAIN\n",
    "    elif mode == 'eval':\n",
    "        mode_key = tf.estimator.ModeKeys.EVAL\n",
    "    else:\n",
    "        tf.logging.error('[input_fn_builder] invalid mode:{}'.format(mode))\n",
    "                         \n",
    "    input_fn = lambda: input_fn_def(files_name_pattern, mode_key, \n",
    "                                    skip_header_lines, num_epochs, batch_size)\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = input_fn_builder(files_name_pattern=CSV_PATH_TRAIN, mode='train', \n",
    "                            num_epochs=STEPS, batch_size=BATCH_TRAIN, skip_header_lines=1)\n",
    "\n",
    "eval_fn = input_fn_builder(files_name_pattern=CSV_PATH_EVAL, mode='eval',\n",
    "                           num_epochs=1, batch_size=BATCH_EVAL, skip_header_lines=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for prediction\n",
    "def serving_input_fn(): \n",
    "    receiver_tensor = {}\n",
    "    for el in HEADER:\n",
    "        receiver_tensor[el] = tf.placeholder(tf.string, [None])\n",
    "\n",
    "    features = {key: tensor\n",
    "                for key, tensor in receiver_tensor.items()\n",
    "                }\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensor)\n",
    "\n",
    "\n",
    "# Train & eval the model and export for prediction\n",
    "def my_train_and_evaluate(model_fn, input_fn, eval_fn, train_steps, params = None):    \n",
    "        \n",
    "    \n",
    "    exporter=tf.estimator.FinalExporter(name='predict', # Needed for prediction\n",
    "                                        serving_input_receiver_fn=serving_input_fn,\n",
    "                                        as_text=False)\n",
    "\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=eval_fn,\n",
    "                                      exporters=exporter, \n",
    "                                      steps=EVAL_STEPS,\n",
    "                                      start_delay_secs = 10, \n",
    "                                      throttle_secs=1,\n",
    "                                      name='eval_spec'\n",
    "                                      )\n",
    "\n",
    "    # Create estimator        \n",
    "    run_config = tf.estimator.RunConfig(tf_random_seed=42, # consistency\n",
    "                                        save_checkpoints_steps = SAVE_CHECKPOINTS_STEPS,\n",
    "                                        keep_checkpoint_max=10\n",
    "                                        )\n",
    "    \n",
    "    my_estimator = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                          model_dir=MODEL_DIR_PATH,\n",
    "                                          params=params,\n",
    "                                          config=run_config\n",
    "                                         )\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = tf.contrib.estimator.stop_if_no_decrease_hook(\n",
    "                                                    my_estimator,\n",
    "                                                    metric_name='my_acc',\n",
    "                                                    max_steps_without_decrease=10000,\n",
    "                                                    min_steps=10000)\n",
    "    # Train spec\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn,\n",
    "                                        max_steps=train_steps,\n",
    "                                        hooks=[early_stopping]\n",
    "                                       )\n",
    "    \n",
    "    # Launch estimator\n",
    "    tf.estimator.train_and_evaluate(my_estimator, train_spec, eval_spec)\n",
    "    tf.logging.info('****[END]**** \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Input hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_encoding(code, tips):\n",
    "    with tf.name_scope('Pad_encoder') as scope:\n",
    "        if tips:\n",
    "            zeros_dims = tf.stack([tf.shape(code)[0], 34]) \n",
    "        else:\n",
    "            zeros_dims = tf.stack([tf.shape(code)[0], 24]) \n",
    "        pad_one_hot = tf.fill(zeros_dims, 0.0)\n",
    "        return pad_one_hot   \n",
    "\n",
    "    \n",
    "def tips_converter(peg):\n",
    "     with tf.name_scope('Tips_encoder_slave') as scope:\n",
    "        peg_ones = tf.ones(shape=[peg]) \n",
    "        peg_zeros = tf.zeros(shape=[5 - peg]) \n",
    "        peg_encoded = tf.concat([peg_ones, peg_zeros], axis=0)\n",
    "        return peg_encoded\n",
    "\n",
    "    \n",
    "def guess_and_psw_encoding(code, tips, pegs_table, tips_table):\n",
    "    with tf.name_scope('Encoder') as scope:\n",
    "        with tf.name_scope('Pegs_extractor') as scope:\n",
    "            for idx in range(4):\n",
    "                piece = tf.strings.substr(code, idx, 1)\n",
    "                piece_id = pegs_table.lookup(piece)\n",
    "                piece_one_hot = tf.one_hot(piece_id, 6) # [A-->F] = 6\n",
    "                if idx == 0:\n",
    "                    code_one_hot = piece_one_hot\n",
    "                else:\n",
    "                    code_one_hot = tf.concat([code_one_hot, piece_one_hot],axis=1) \n",
    "\n",
    "        # <code> is the password (last column of csv)\n",
    "        if not tips:\n",
    "            return code_one_hot\n",
    "\n",
    "        # <code> is a guess\n",
    "        with tf.name_scope('Tips_encoder_Master') as scope:\n",
    "            blk_peg = tf.strings.substr(code, 4, 1) # Extract tips: e.g. '0'\n",
    "            wht_peg = tf.strings.substr(code, 5, 1)\n",
    "            blk_peg = tf.to_float(tips_table.lookup(blk_peg)) # string to number: e.g. '0'\n",
    "            wht_peg = tf.to_float(tips_table.lookup(wht_peg))\n",
    "            blk_peg = tf.add(blk_peg, tf.constant(1,dtype=tf.float32)) # e.g. '0' will have one '1'\n",
    "            wht_peg = tf.add(wht_peg, tf.constant(1,dtype=tf.float32))\n",
    "            blk_peg = tf.map_fn(tips_converter, blk_peg) # e.g. '0' --> [10000] \n",
    "            wht_peg = tf.map_fn(tips_converter, wht_peg)\n",
    "            code_one_hot = tf.concat([code_one_hot, blk_peg], axis=1) # Attach peg to the psw encoded\n",
    "            code_one_hot = tf.concat([code_one_hot, wht_peg], axis=1) \n",
    "\n",
    "            return code_one_hot\n",
    "\n",
    "\n",
    "def one_hot_converter(code, tips=True): # code.shape = (?,) - where ? is the batch size\n",
    "    \"\"\" \n",
    "    Convert each element of a match in machine readable data:\n",
    "    Code: A --> [100000] B --> [010000] C --> [001000] ... F --> [000001]\n",
    "    Tips: 0 --> [1000]   1 --> [11000]  2 --> [11100]  ... 4 --> [11111]\n",
    "    \"\"\"        \n",
    "    \n",
    "    # Char to Int mapping, the position will be the idx\n",
    "    with tf.name_scope('Hot_encoding_slave') as scope:\n",
    "        mapping_strings = tf.constant(['A', 'B', 'C', 'D', 'E', 'F'])\n",
    "        mapping_tips = tf.constant(['0','1','2','3','4'])\n",
    "\n",
    "        pegs_table = tf.contrib.lookup.index_table_from_tensor(mapping=mapping_strings, default_value=-1)\n",
    "        tips_table = tf.contrib.lookup.index_table_from_tensor(mapping=mapping_tips, default_value=-1)\n",
    "\n",
    "        # Check if code is pad\n",
    "        is_pad = tf.strings.regex_full_match(code, tf.constant('<pad>'))        \n",
    "        is_pad = tf.math.reduce_all(is_pad)\n",
    "\n",
    "        # Code encoding\n",
    "        code_one_hot = tf.cond(is_pad, \\\n",
    "                               lambda: pad_encoding(code, tips), \\\n",
    "                               lambda: guess_and_psw_encoding(code, tips, pegs_table, tips_table))     \n",
    "    \n",
    "        return code_one_hot\n",
    "\n",
    "\n",
    "def feature_encoder(match):\n",
    "    with tf.name_scope('Hot_encoding_match') as scope:\n",
    "        match_converted = []\n",
    "        for guess in match.values():\n",
    "            code_one_hot = one_hot_converter(guess, tips=True)\n",
    "            match_converted.append(code_one_hot)\n",
    "        return match_converted\n",
    "\n",
    "\n",
    "def labels_encoder(password):\n",
    "    with tf.name_scope('Hot_encoding_psw') as scope:\n",
    "        password_hot = one_hot_converter(password, tips=False)\n",
    "        return password_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "### 4.4 Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Maxout\n",
    "def max_out(inputs, num_units, axis=None):\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    if shape[0] is None:\n",
    "        shape[0] = -1\n",
    "    if axis is None:  # Assume that channel is the last dimension\n",
    "        axis = -1\n",
    "    num_channels = shape[axis]\n",
    "    if num_channels % num_units:\n",
    "        raise ValueError('number of features({}) is not '\n",
    "                         'a multiple of num_units({})'.format(num_channels, num_units))\n",
    "    shape[axis] = num_units\n",
    "    shape += [num_channels // num_units]\n",
    "    outputs = tf.reduce_max(tf.reshape(inputs, shape), -1, keep_dims=False) # TODO: change reduce_max (deprecated)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model function\n",
    "def test_model_fn(features, labels, mode, params=None):\n",
    "    \n",
    "    ##################\n",
    "    # INPUT ENCODING \n",
    "    ##################\n",
    "    tf.logging.debug('Params:{}'.format(params))\n",
    "    with tf.name_scope('Hot_encoding_master') as scope:\n",
    "        \n",
    "        psw = features.pop('PASSWORD') # Used features.pop instead of labels because \"goalReduced\"        \n",
    "        psw_encoded = labels_encoder(psw) #(?, 24)\n",
    "        goal_pos_start = GOAL_POS * 6\n",
    "        psw_cutted = psw_encoded[:,goal_pos_start:goal_pos_start+6] # Reduced Goal\n",
    "    \n",
    "        match_encoded = feature_encoder(features) # [(?,?=34) ...] x 10\n",
    "        match_encoded = tf.stack(match_encoded, axis=1) # (?,10,?=34)\n",
    "        match_encoded = tf.reshape(match_encoded, shape=[-1,10,34])\n",
    "        match_encoded = tf.unstack(match_encoded, axis=1) # [(?,34)...] x 10\n",
    "        \n",
    "        # Add psw pre-predicted\n",
    "        psw_pre_predicted = psw_encoded[:,0:GOAL_POS*6] #(?,[0,6,12,18]) See the psw you don't need to predict\n",
    "        paddings = [[0,0],[0, (4-GOAL_POS) * 6 + 10]]\n",
    "        psw_pre_predicted_padded = tf.pad(psw_pre_predicted, paddings) #(?,34)\n",
    "        match_encoded.append(psw_pre_predicted_padded)  # [(?,34)...,(?,[0-6-12-18])] x 11\n",
    "    \n",
    "    \n",
    "    ####################\n",
    "    # NETWORK STRUCTURE\n",
    "    ####################\n",
    "    \n",
    "    # Network design\n",
    "    with tf.name_scope('Network_Design') as scope:\n",
    "        lstm_fw_cell = rnn_cell.LSTMCell(LSTM_SIZE, forget_bias=FW_FORGET_BIAS, name=\"fw_cell\")\n",
    "        lstm_bw_cell = rnn_cell.LSTMCell(LSTM_SIZE, forget_bias=BW_FORGET_BIAS, name=\"bw_cell\")\n",
    "        \n",
    "        bilstm, _, _ = static_bidirectional_rnn(lstm_fw_cell, \n",
    "                                                lstm_bw_cell, \n",
    "                                                inputs=match_encoded, \n",
    "                                                dtype=tf.float32)\n",
    "        \n",
    "        lstm_output = tf.stack(bilstm, axis=0) # (11, ?, 128)\n",
    "        \n",
    "        # Attention system\n",
    "        with tf.variable_scope('Attention_system') as scope:\n",
    "            inputs = tf.transpose(lstm_output, [1, 0, 2]) #(T,B,D) => (B,T,D) \n",
    "            hidden_size = inputs.shape[2].value \n",
    "            w_omega = tf.Variable(tf.random_normal([hidden_size, ATTENTION_SIZE], stddev=0.1), name=\"w_omega\")\n",
    "            b_omega = tf.Variable(tf.random_normal([ATTENTION_SIZE], stddev=0.1), name=\"b_omega\")\n",
    "            u_omega = tf.Variable(tf.random_normal([ATTENTION_SIZE], stddev=0.1), name=\"u_omega\")\n",
    "            with tf.name_scope('1_v_build'):\n",
    "                v = tf.tanh(tf.tensordot(inputs, w_omega, axes=1) + b_omega)\n",
    "            vu = tf.tensordot(v, u_omega, axes=1, name='2_vu_4softmax')\n",
    "            alphas = tf.nn.softmax(vu, name='3_softmax_build_alphas')       \n",
    "            representation = tf.reduce_sum(inputs * tf.expand_dims(alphas, -1), 1,name='4_r_build')\n",
    "        \n",
    "        is_training = True if mode == tf.estimator.ModeKeys.TRAIN else False\n",
    "        representation = tf.layers.dropout(representation,\n",
    "                                           rate=DROP_REPRESENTATION,\n",
    "                                           training=is_training)\n",
    "        \n",
    "        representation = max_out(representation, MAXOUT_SIZE)\n",
    "        logits = tf.layers.dense(inputs=representation, units=6, name='logits_layer', activation=tf.nn.softmax) # (?, 6)\n",
    "\n",
    "    \n",
    "    #####################\n",
    "    # 1 - PREDICT MODE\n",
    "    ####################\n",
    "    \n",
    "    # Prediction Form\n",
    "    with tf.name_scope('Prediction_Prepare') as scope:\n",
    "        piece_id = tf.math.argmax(logits, axis=1) \n",
    "        pieces_one_hot = tf.one_hot(piece_id, 6) # convert logits to nearest legal peg\n",
    "        prediction = pieces_one_hot\n",
    "        \n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        probabilities = logits # fully_connected have already softmax \n",
    "        predictions = {'Prediction': prediction, 'probabilites': probabilities, 'logits': logits}\n",
    "        export_outputs = {'prediction': tf.estimator.export.PredictOutput(predictions)}\n",
    "        return tf.estimator.EstimatorSpec(mode, \n",
    "                                          predictions=predictions, \n",
    "                                          export_outputs=export_outputs)\n",
    "    \n",
    "    #############\n",
    "    # METRICS\n",
    "    #############\n",
    "    \n",
    "    # Custom accuracy - Numbers of \"1\" that coincide between hot(psw_predicted) and hot(psw)\n",
    "    with tf.name_scope('Custom_accuracy') as scope:\n",
    "        equality = tf.equal(prediction, psw_cutted)\n",
    "        equality = tf.math.reduce_all(equality, axis=1)\n",
    "        custom_accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "        \n",
    "        ones_acc = tf.math.multiply(psw_cutted, prediction)\n",
    "        ones_acc = tf.math.reduce_sum(ones_acc, axis=1)\n",
    "    \n",
    "    \n",
    "    with tf.name_scope('Custom_metrics'):\n",
    "        accuracy_of_ones = tf.metrics.accuracy(labels=tf.fill(tf.shape(ones_acc), 1.0), \n",
    "                                               predictions=ones_acc, \n",
    "                                               name='acc_of_ones')\n",
    "        \n",
    "        accuracy = tf.metrics.accuracy(labels=psw_cutted, \n",
    "                                       predictions=prediction, \n",
    "                                       name='my_accuracy')\n",
    "\n",
    "        precision = tf.metrics.precision(labels=psw_cutted, \n",
    "                                         predictions=prediction, \n",
    "                                         name='my_precision')\n",
    "\n",
    "        tf.summary.scalar('my_acc', accuracy[1])\n",
    "        tf.summary.scalar('my_prec', precision[1])\n",
    "        tf.summary.scalar('my_acc_of_one', accuracy_of_ones[1])\n",
    "        \n",
    "        \n",
    "    # Loss\n",
    "    with tf.name_scope('Loss_prepare') as scope:\n",
    "        loss = tf.losses.mean_pairwise_squared_error(labels=psw_cutted, predictions=logits) # [!] model.info\n",
    "        if L2_ACTIVATED:\n",
    "            l2_regularizer = tf.contrib.layers.l2_regularizer(scale=L2_SCALE, scope='l2_regularization') \n",
    "            weights = tf.trainable_variables() \n",
    "            regularization_penalty = tf.contrib.layers.apply_regularization(l2_regularizer, weights)\n",
    "            regularized_loss = loss + regularization_penalty\n",
    "            loss = regularized_loss\n",
    "            \n",
    "            \n",
    "    #################\n",
    "    # DEBUG INSIGHTS\n",
    "    #################\n",
    "    \n",
    "    dict_debug = {}\n",
    "    dict_debug['Match encoded[0]'] = match_encoded[0]\n",
    "    dict_debug['Logits'] = logits\n",
    "    dict_debug['Prediction'] = prediction\n",
    "    dict_debug['Password'] = psw_encoded\n",
    "    dict_debug['Password_cutted'] = psw_cutted\n",
    "    dict_debug['Equality'] = equality\n",
    "    dict_debug['Accuracy_of_ones'] = ones_acc\n",
    "    dict_debug['Real_Accuracy'] = custom_accuracy\n",
    "    dict_debug['Psw_Pre_Predicted'] = psw_pre_predicted\n",
    "    dict_debug['Psw_Pre_Predicted_Padded_1'] = psw_pre_predicted_padded[:,:18]\n",
    "    dict_debug['Psw_Pre_Predicted_Padded_2'] = psw_pre_predicted_padded[:,18:]\n",
    "    \n",
    "    # Hooks\n",
    "    debug_hook = [tf.train.LoggingTensorHook(dict_debug, every_n_iter=30)] if DEBUG_HOOK else []     \n",
    "  \n",
    "\n",
    "        \n",
    "    #####################\n",
    "    # TRAIN & EVAL MODE\n",
    "    ####################\n",
    "    \n",
    "    # 2 - Evaluation mode\n",
    "    if mode == tf.estimator.ModeKeys.EVAL: \n",
    "        custom_metrics = {'my_acc':accuracy, 'my_prec':precision, 'my_acc_of_one':accuracy_of_ones}\n",
    "        return tf.estimator.EstimatorSpec(mode, \n",
    "                                          loss=loss,\n",
    "                                          eval_metric_ops=custom_metrics)\n",
    "    \n",
    "    # 3 - Train mode\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=ALPHA)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode,\n",
    "                                      loss=loss,\n",
    "                                      training_hooks = debug_hook,\n",
    "                                      train_op=train_op\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## 5. Run\n",
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fbb7b5c3f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(MODEL_DIR_PATH, exist_ok=True)\n",
    "%tensorboard --logdir {MODEL_DIR_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_model.info saved\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##########\n",
    "# RUN\n",
    "##########\n",
    "def save_params(params, path):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(params, f, indent=1, sort_keys=True)\n",
    "        print('{} saved'.format(path))\n",
    "\n",
    "save_params(model_params,\"temp_model.info\")\n",
    "\n",
    "time_start = time.time()\n",
    "my_train_and_evaluate(test_model_fn, input_fn, eval_fn, STEPS, model_params)\n",
    "total_time = time.time() - time_start\n",
    "\n",
    "time_consumed = str(datetime.timedelta(seconds=total_time))[:-7]\n",
    "model_params['train_duration'] = time_consumed\n",
    "\n",
    "save_params(model_params, MODEL_DIR_PATH+\"/model.info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm temp_model.info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
