{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM with _goalReduced_\n",
    "## Characteristics\n",
    "1. **Network type**: BiLSTM cells with Attention System<br><br>\n",
    "2. **goalReduced**: the goal of this network is predict **one** of the goal letter<br>\n",
    "    2.1 You must train 4 of those networks, one for each goal's letter<br>\n",
    "    2.2 The network that predict position *N* of the goal take in input *N-1* goal's letters<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## 1. Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '__py*': No such file or directory\n",
      "rm: cannot remove 'tf.log': No such file or directory\n",
      "rm: cannot remove 'temp_model.info': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#!rm -r model_*\n",
    "!rm -r __py*\n",
    "!rm tf.log\n",
    "!rm temp_model.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:version:1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import data\n",
    "from tensorflow.nn import rnn_cell\n",
    "from tensorflow.nn import static_bidirectional_rnn\n",
    "import multiprocessing\n",
    "import random as rnd\n",
    "import logging\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "tf.logging.info('version:{}'.format(tf.__version__))\n",
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "random_int = rnd.randint(0,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "## 2. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General params\n",
    "NETWORK_TYPE, GOAL_TYPE = 'BiLSTM_AttentionSystem', 'goalReduced'\n",
    "LOGGING_TO_FILE = True\n",
    "\n",
    "# Debug params\n",
    "DEBUG_HOOK = False\n",
    "\n",
    "\n",
    "# Input params\n",
    "\n",
    "CSV_PATH_TRAIN = \"../database/dbML/knuthFast/knuthFast_2019-07-30_0.9_75844_train.csv\"\n",
    "CSV_PATH_EVAL = \"../database/dbML/knuthFast/knuthFast_2019-07-30_0.9_8516_eval.csv\"\n",
    "\n",
    "\n",
    "# Goal position\n",
    "GOAL_POS = 0 #[0-3]\n",
    "\n",
    "\n",
    "# Model dir\n",
    "MODEL_DIR_PATH = \"../networks/Trained/hopeful/model_dir_647_0/\"\n",
    "\n",
    "\n",
    "# Train params\n",
    "LEN_TRAIN_DB = 75844\n",
    "EPOCHS = 10\n",
    "ALPHA = 0.001\n",
    "\n",
    "\n",
    "# Network\n",
    "FW_FORGET_BIAS = 1\n",
    "BW_FORGET_BIAS = 1\n",
    "LSTM_SIZE = 256\n",
    "ATTENTION_SIZE = 256\n",
    "MAXOUT_SIZE = 256\n",
    "DROP_REPRESENTATION = 0.3 \n",
    "\n",
    "L2_ACTIVATED = True\n",
    "L2_SCALE = 0.001\n",
    "\n",
    "\n",
    "# Input \n",
    "BATCH_TRAIN = 4\n",
    "MULTI_THREADING = True\n",
    "\n",
    "# Eval\n",
    "BATCH_EVAL = 4\n",
    "SHUFFLE_EVAL = True\n",
    "EVAL_STEPS = None\n",
    "NUM_EVALS = EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Epochs to steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 10 epochs are equivalent to 189610 steps\n",
      "[INFO] Eval will be executed each 18961 steps for a total of 10 times\n"
     ]
    }
   ],
   "source": [
    "STEPS = int(EPOCHS * (LEN_TRAIN_DB / BATCH_TRAIN))\n",
    "SAVE_CHECKPOINTS_STEPS = int(STEPS / NUM_EVALS) # Do eval each N steps (and save the model)\n",
    "\n",
    "print('[INFO] {} epochs are equivalent to {} steps'.format(EPOCHS, STEPS))\n",
    "print('[INFO] Eval will be executed each {} steps for a total of {} times'.format(SAVE_CHECKPOINTS_STEPS, NUM_EVALS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Persistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What save in model.info\n",
    "model_params = {}\n",
    "model_params['_NETWORK_TYPE'] = NETWORK_TYPE\n",
    "model_params['CSV_PATH_TRAIN'] = CSV_PATH_TRAIN\n",
    "model_params['CSV_PATH_EVAL'] = CSV_PATH_EVAL\n",
    "model_params['MODEL_DIR_PATH'] = MODEL_DIR_PATH\n",
    "model_params['EPOCHS'] = EPOCHS\n",
    "model_params['ALPHA'] = ALPHA\n",
    "model_params['FW_FORGET_BIAS'] = FW_FORGET_BIAS\n",
    "model_params['BW_FORGET_BIAS'] = BW_FORGET_BIAS\n",
    "model_params['LSTM_SIZE'] = LSTM_SIZE\n",
    "model_params['NUM_EVALS'] = NUM_EVALS\n",
    "model_params['BATCH_TRAIN'] = BATCH_TRAIN\n",
    "model_params['BATCH_EVAL'] = BATCH_EVAL\n",
    "model_params['SHUFFLE_EVAL'] = SHUFFLE_EVAL\n",
    "model_params['EVAL_STEPS'] = EVAL_STEPS\n",
    "model_params['MULTI_THREADING'] = MULTI_THREADING\n",
    "model_params['INPUT_ENCODING'] = 'Peg: Hot encoding, Tips: One Hot Encoding'\n",
    "model_params['GOAL'] = GOAL_TYPE\n",
    "model_params['ATTENTION_SIZE'] = ATTENTION_SIZE\n",
    "model_params['MAXOUT_SIZE'] = MAXOUT_SIZE\n",
    "model_params['DROP_REPRESENTATION']= DROP_REPRESENTATION\n",
    "model_params['GOAL_POS'] = GOAL_POS\n",
    "model_params['loss_fn'] = \"mean_pairwise_squared_error\"\n",
    "if L2_ACTIVATED: model_params['L2_SCALE'] = L2_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOGGING_TO_FILE:\n",
    "    tf_log = logging.getLogger('tensorflow')\n",
    "    for el in tf_log.handlers:\n",
    "        tf_log.removeHandler(el)\n",
    "    fh = logging.FileHandler('tf.log')\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    tf_log.addHandler(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "## 4. Estimator components\n",
    "### 4.1 Input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_NAME = ['Guess 1', 'Guess 2', 'Guess 3', 'Guess 4', 'Guess 5',\n",
    "          'Guess 6', 'Guess 7', 'Guess 8', 'Guess 9', 'Guess 10']\n",
    "\n",
    "TARGET_NAME = 'PASSWORD'\n",
    "\n",
    "HEADER = FEATURES_NAME + [TARGET_NAME]\n",
    "\n",
    "HEADER_DEFAULTS = [['<pad>'], ['<pad>'],['<pad>'],['<pad>'],['<pad>'],['<pad>'],\n",
    "                  ['<pad>'],['<pad>'],['<pad>'],['<pad>'],['<pad>']]\n",
    "\n",
    "def input_fn_builder(files_name_pattern, mode, skip_header_lines=0, num_epochs=1, batch_size=32):   \n",
    "    '''\n",
    "    Input function builder, the input_fn returnet could be used\n",
    "    in order to feed an tf.estimator.\n",
    "    \n",
    "    # Params\n",
    "        mode = {\"train\", \"eval\"}\n",
    "    '''    \n",
    "    \n",
    "    # utils\n",
    "    def parse_csv_row(csv_row):\n",
    "        columns = tf.decode_csv(csv_row, record_defaults=HEADER_DEFAULTS, field_delim=',')\n",
    "        features = dict(zip(HEADER, columns))    \n",
    "        target = features[TARGET_NAME]\n",
    "        return features, target\n",
    "\n",
    "    # input function definition\n",
    "    def input_fn_def(files_name_pattern, mode, skip_header_lines, num_epochs, batch_size):\n",
    "        shuffle = True if mode == tf.estimator.ModeKeys.TRAIN else False\n",
    "        num_threads = multiprocessing.cpu_count() if MULTI_THREADING else 1\n",
    "        buffer_size = 2 * batch_size + 1\n",
    "        file_names = tf.matching_files(files_name_pattern) # <matching_files> accept wildcard\n",
    "        dataset = data.TextLineDataset(filenames=file_names)\n",
    "        dataset = dataset.skip(skip_header_lines)\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size)\n",
    "        dataset = dataset.map(lambda csv_row: parse_csv_row(csv_row), \n",
    "                              num_parallel_calls=num_threads)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.repeat(num_epochs)\n",
    "        dataset = dataset.prefetch(buffer_size)\n",
    "        return dataset\n",
    "    \n",
    "    # function builder\n",
    "    if mode == 'train':\n",
    "        mode_key = tf.estimator.ModeKeys.TRAIN\n",
    "    elif mode == 'eval':\n",
    "        mode_key = tf.estimator.ModeKeys.EVAL\n",
    "    else:\n",
    "        tf.logging.error('[input_fn_builder] invalid mode:{}'.format(mode))\n",
    "                         \n",
    "    input_fn = lambda: input_fn_def(files_name_pattern, mode_key, \n",
    "                                    skip_header_lines, num_epochs, batch_size)\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = input_fn_builder(files_name_pattern=CSV_PATH_TRAIN, mode='train', \n",
    "                            num_epochs=STEPS, batch_size=BATCH_TRAIN, skip_header_lines=1)\n",
    "\n",
    "eval_fn = input_fn_builder(files_name_pattern=CSV_PATH_EVAL, mode='eval',\n",
    "                           num_epochs=1, batch_size=BATCH_EVAL, skip_header_lines=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for prediction\n",
    "def serving_input_fn(): \n",
    "    receiver_tensor = {}\n",
    "    for el in HEADER:\n",
    "        receiver_tensor[el] = tf.placeholder(tf.string, [None])\n",
    "\n",
    "    features = {key: tensor\n",
    "                for key, tensor in receiver_tensor.items()\n",
    "                }\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensor)\n",
    "\n",
    "\n",
    "# Train & eval the model and export for prediction\n",
    "def my_train_and_evaluate(model_fn, input_fn, eval_fn, train_steps, params = None):    \n",
    "        \n",
    "    \n",
    "    exporter=tf.estimator.FinalExporter(name='predict', # Needed for prediction\n",
    "                                        serving_input_receiver_fn=serving_input_fn,\n",
    "                                        as_text=False)\n",
    "\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=eval_fn,\n",
    "                                      exporters=exporter, \n",
    "                                      steps=EVAL_STEPS,\n",
    "                                      start_delay_secs = 10, \n",
    "                                      throttle_secs=1,\n",
    "                                      name='eval_spec'\n",
    "                                      )\n",
    "\n",
    "    # Create estimator        \n",
    "    run_config = tf.estimator.RunConfig(tf_random_seed=42, # consistency\n",
    "                                        save_checkpoints_steps = SAVE_CHECKPOINTS_STEPS,\n",
    "                                        keep_checkpoint_max=10\n",
    "                                        )\n",
    "    \n",
    "    my_estimator = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                          model_dir=MODEL_DIR_PATH,\n",
    "                                          params=params,\n",
    "                                          config=run_config\n",
    "                                         )\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = tf.contrib.estimator.stop_if_no_decrease_hook(\n",
    "                                                    my_estimator,\n",
    "                                                    metric_name='my_acc',\n",
    "                                                    max_steps_without_decrease=10000,\n",
    "                                                    min_steps=10000)\n",
    "    # Train spec\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn,\n",
    "                                        max_steps=train_steps,\n",
    "                                        hooks=[early_stopping]\n",
    "                                       )\n",
    "    \n",
    "    # Launch estimator\n",
    "    tf.estimator.train_and_evaluate(my_estimator, train_spec, eval_spec)\n",
    "    tf.logging.info('****[END]**** \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_estimator(model_fn, input_fn, eval_fn, train_steps, params = None):    \n",
    "        \n",
    "    \n",
    "    exporter=tf.estimator.FinalExporter(name='predict', # Needed for prediction\n",
    "                                        serving_input_receiver_fn=serving_input_fn,\n",
    "                                        as_text=False)\n",
    "\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=eval_fn,\n",
    "                                      exporters=exporter, \n",
    "                                      steps=EVAL_STEPS,\n",
    "                                      start_delay_secs = 10, \n",
    "                                      throttle_secs=1,\n",
    "                                      name='eval_spec'\n",
    "                                      )\n",
    "\n",
    "    # Create estimator        \n",
    "    run_config = tf.estimator.RunConfig(tf_random_seed=42, # consistency\n",
    "                                        save_checkpoints_steps = SAVE_CHECKPOINTS_STEPS,\n",
    "                                        keep_checkpoint_max=10\n",
    "                                        )\n",
    "    \n",
    "    my_estimator = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                          model_dir=MODEL_DIR_PATH,\n",
    "                                          params=params,\n",
    "                                          config=run_config\n",
    "                                         )\n",
    "    return my_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Input hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_encoding(code, tips):\n",
    "    with tf.name_scope('Pad_encoder') as scope:\n",
    "        if tips:\n",
    "            zeros_dims = tf.stack([tf.shape(code)[0], 34]) \n",
    "        else:\n",
    "            zeros_dims = tf.stack([tf.shape(code)[0], 24]) \n",
    "        pad_one_hot = tf.fill(zeros_dims, 0.0)\n",
    "        return pad_one_hot   \n",
    "\n",
    "    \n",
    "def tips_converter(peg):\n",
    "     with tf.name_scope('Tips_encoder_slave') as scope:\n",
    "        peg_ones = tf.ones(shape=[peg]) \n",
    "        peg_zeros = tf.zeros(shape=[5 - peg]) \n",
    "        peg_encoded = tf.concat([peg_ones, peg_zeros], axis=0)\n",
    "        return peg_encoded\n",
    "\n",
    "    \n",
    "def guess_and_psw_encoding(code, tips, pegs_table, tips_table):\n",
    "    with tf.name_scope('Encoder') as scope:\n",
    "        with tf.name_scope('Pegs_extractor') as scope:\n",
    "            for idx in range(4):\n",
    "                piece = tf.strings.substr(code, idx, 1)\n",
    "                piece_id = pegs_table.lookup(piece)\n",
    "                piece_one_hot = tf.one_hot(piece_id, 6) # [A-->F] = 6\n",
    "                if idx == 0:\n",
    "                    code_one_hot = piece_one_hot\n",
    "                else:\n",
    "                    code_one_hot = tf.concat([code_one_hot, piece_one_hot],axis=1) \n",
    "\n",
    "        # <code> is the password (last column of csv)\n",
    "        if not tips:\n",
    "            return code_one_hot\n",
    "\n",
    "        # <code> is a guess\n",
    "        with tf.name_scope('Tips_encoder_Master') as scope:\n",
    "            blk_peg = tf.strings.substr(code, 4, 1) # Extract tips: e.g. '0'\n",
    "            wht_peg = tf.strings.substr(code, 5, 1)\n",
    "            blk_peg = tf.to_float(tips_table.lookup(blk_peg)) # string to number: e.g. '0'\n",
    "            wht_peg = tf.to_float(tips_table.lookup(wht_peg))\n",
    "            blk_peg = tf.add(blk_peg, tf.constant(1,dtype=tf.float32)) # e.g. '0' will have one '1'\n",
    "            wht_peg = tf.add(wht_peg, tf.constant(1,dtype=tf.float32))\n",
    "            blk_peg = tf.map_fn(tips_converter, blk_peg) # e.g. '0' --> [10000] \n",
    "            wht_peg = tf.map_fn(tips_converter, wht_peg)\n",
    "            code_one_hot = tf.concat([code_one_hot, blk_peg], axis=1) # Attach peg to the psw encoded\n",
    "            code_one_hot = tf.concat([code_one_hot, wht_peg], axis=1) \n",
    "\n",
    "            return code_one_hot\n",
    "\n",
    "\n",
    "def one_hot_converter(code, tips=True): # code.shape = (?,) - where ? is the batch size\n",
    "    \"\"\" \n",
    "    Convert each element of a match in machine readable data:\n",
    "    Code: A --> [100000] B --> [010000] C --> [001000] ... F --> [000001]\n",
    "    Tips: 0 --> [1000]   1 --> [11000]  2 --> [11100]  ... 4 --> [11111]\n",
    "    \"\"\"        \n",
    "    \n",
    "    # Char to Int mapping, the position will be the idx\n",
    "    with tf.name_scope('Hot_encoding_slave') as scope:\n",
    "        mapping_strings = tf.constant(['A', 'B', 'C', 'D', 'E', 'F'])\n",
    "        mapping_tips = tf.constant(['0','1','2','3','4'])\n",
    "\n",
    "        pegs_table = tf.contrib.lookup.index_table_from_tensor(mapping=mapping_strings, default_value=-1)\n",
    "        tips_table = tf.contrib.lookup.index_table_from_tensor(mapping=mapping_tips, default_value=-1)\n",
    "\n",
    "        # Check if code is pad\n",
    "        is_pad = tf.strings.regex_full_match(code, tf.constant('<pad>'))        \n",
    "        is_pad = tf.math.reduce_all(is_pad)\n",
    "\n",
    "        # Code encoding\n",
    "        code_one_hot = tf.cond(is_pad, \\\n",
    "                               lambda: pad_encoding(code, tips), \\\n",
    "                               lambda: guess_and_psw_encoding(code, tips, pegs_table, tips_table))     \n",
    "    \n",
    "        return code_one_hot\n",
    "\n",
    "\n",
    "def feature_encoder(match):\n",
    "    with tf.name_scope('Hot_encoding_match') as scope:\n",
    "        match_converted = []\n",
    "        for guess in match.values():\n",
    "            code_one_hot = one_hot_converter(guess, tips=True)\n",
    "            match_converted.append(code_one_hot)\n",
    "        return match_converted\n",
    "\n",
    "\n",
    "def labels_encoder(password):\n",
    "    with tf.name_scope('Hot_encoding_psw') as scope:\n",
    "        password_hot = one_hot_converter(password, tips=False)\n",
    "        return password_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "### 4.4 Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Maxout\n",
    "def max_out(inputs, num_units, axis=None):\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    if shape[0] is None:\n",
    "        shape[0] = -1\n",
    "    if axis is None:  # Assume that channel is the last dimension\n",
    "        axis = -1\n",
    "    num_channels = shape[axis]\n",
    "    if num_channels % num_units:\n",
    "        raise ValueError('number of features({}) is not '\n",
    "                         'a multiple of num_units({})'.format(num_channels, num_units))\n",
    "    shape[axis] = num_units\n",
    "    shape += [num_channels // num_units]\n",
    "    outputs = tf.reduce_max(tf.reshape(inputs, shape), -1, keep_dims=False) # TODO: change reduce_max (deprecated)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model function\n",
    "def test_model_fn(features, labels, mode, params=None):\n",
    "    \n",
    "    ##################\n",
    "    # INPUT ENCODING \n",
    "    ##################\n",
    "    tf.logging.debug('Params:{}'.format(params))\n",
    "    with tf.name_scope('Hot_encoding_master') as scope:\n",
    "        \n",
    "        psw = features.pop('PASSWORD') # Used features.pop instead of labels because \"goalReduced\"        \n",
    "        psw_encoded = labels_encoder(psw) #(?, 24)\n",
    "        goal_pos_start = GOAL_POS * 6\n",
    "        psw_cutted = psw_encoded[:,goal_pos_start:goal_pos_start+6] # Reduced Goal\n",
    "    \n",
    "        match_encoded = feature_encoder(features) # [(?,?=34) ...] x 10\n",
    "        match_encoded = tf.stack(match_encoded, axis=1) # (?,10,?=34)\n",
    "        match_encoded = tf.reshape(match_encoded, shape=[-1,10,34])\n",
    "        match_encoded = tf.unstack(match_encoded, axis=1) # [(?,34)...] x 10\n",
    "        \n",
    "        # Add psw pre-predicted\n",
    "        psw_pre_predicted = psw_encoded[:,0:GOAL_POS*6] #(?,[0,6,12,18]) See the psw you don't need to predict\n",
    "        paddings = [[0,0],[0, (4-GOAL_POS) * 6 + 10]]\n",
    "        psw_pre_predicted_padded = tf.pad(psw_pre_predicted, paddings) #(?,34)\n",
    "        match_encoded.append(psw_pre_predicted_padded)  # [(?,34)...,(?,[0-6-12-18])] x 11\n",
    "    \n",
    "    \n",
    "    ####################\n",
    "    # NETWORK STRUCTURE\n",
    "    ####################\n",
    "    \n",
    "    # Network design\n",
    "    with tf.name_scope('Network_Design') as scope:\n",
    "        lstm_fw_cell = rnn_cell.LSTMCell(LSTM_SIZE, forget_bias=FW_FORGET_BIAS, name=\"fw_cell\")\n",
    "        lstm_bw_cell = rnn_cell.LSTMCell(LSTM_SIZE, forget_bias=BW_FORGET_BIAS, name=\"bw_cell\")\n",
    "        \n",
    "        bilstm, _, _ = static_bidirectional_rnn(lstm_fw_cell, \n",
    "                                                lstm_bw_cell, \n",
    "                                                inputs=match_encoded, \n",
    "                                                dtype=tf.float32)\n",
    "        \n",
    "        lstm_output = tf.stack(bilstm, axis=0) # (11, ?, 128)\n",
    "        \n",
    "        # Attention system\n",
    "        with tf.variable_scope('Attention_system') as scope:\n",
    "            inputs = tf.transpose(lstm_output, [1, 0, 2]) #(T,B,D) => (B,T,D) \n",
    "            hidden_size = inputs.shape[2].value \n",
    "            w_omega = tf.Variable(tf.random_normal([hidden_size, ATTENTION_SIZE], stddev=0.1), name=\"w_omega\")\n",
    "            b_omega = tf.Variable(tf.random_normal([ATTENTION_SIZE], stddev=0.1), name=\"b_omega\")\n",
    "            u_omega = tf.Variable(tf.random_normal([ATTENTION_SIZE], stddev=0.1), name=\"u_omega\")\n",
    "            with tf.name_scope('1_v_build'):\n",
    "                v = tf.tanh(tf.tensordot(inputs, w_omega, axes=1) + b_omega)\n",
    "            vu = tf.tensordot(v, u_omega, axes=1, name='2_vu_4softmax')\n",
    "            alphas = tf.nn.softmax(vu, name='3_softmax_build_alphas')       \n",
    "            representation = tf.reduce_sum(inputs * tf.expand_dims(alphas, -1), 1,name='4_r_build')\n",
    "        \n",
    "        is_training = True if mode == tf.estimator.ModeKeys.TRAIN else False\n",
    "        representation = tf.layers.dropout(representation,\n",
    "                                           rate=DROP_REPRESENTATION,\n",
    "                                           training=is_training)\n",
    "        \n",
    "        representation = max_out(representation, MAXOUT_SIZE)\n",
    "        logits = tf.layers.dense(inputs=representation, units=6, name='logits_layer', activation=tf.nn.softmax) # (?, 6)\n",
    "\n",
    "    \n",
    "    #####################\n",
    "    # 1 - PREDICT MODE\n",
    "    ####################\n",
    "    \n",
    "    # Prediction Form\n",
    "    with tf.name_scope('Prediction_Prepare') as scope:\n",
    "        piece_id = tf.math.argmax(logits, axis=1) \n",
    "        pieces_one_hot = tf.one_hot(piece_id, 6) # convert logits to nearest legal peg\n",
    "        prediction = pieces_one_hot\n",
    "        \n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        probabilities = logits # fully_connected have already softmax \n",
    "        predictions = {'Prediction': prediction, 'probabilites': probabilities, 'logits': logits}\n",
    "        export_outputs = {'prediction': tf.estimator.export.PredictOutput(predictions)}\n",
    "        return tf.estimator.EstimatorSpec(mode, \n",
    "                                          predictions=predictions, \n",
    "                                          export_outputs=export_outputs)\n",
    "    \n",
    "    #############\n",
    "    # METRICS\n",
    "    #############\n",
    "    \n",
    "    # Custom accuracy - Numbers of \"1\" that coincide between hot(psw_predicted) and hot(psw)\n",
    "    with tf.name_scope('Custom_accuracy') as scope:\n",
    "        equality = tf.equal(prediction, psw_cutted)\n",
    "        equality = tf.math.reduce_all(equality, axis=1)\n",
    "        custom_accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "        \n",
    "        ones_acc = tf.math.multiply(psw_cutted, prediction)\n",
    "        ones_acc = tf.math.reduce_sum(ones_acc, axis=1)\n",
    "    \n",
    "    \n",
    "    with tf.name_scope('Custom_metrics'):\n",
    "        accuracy_of_ones = tf.metrics.accuracy(labels=tf.fill(tf.shape(ones_acc), 1.0), \n",
    "                                               predictions=ones_acc, \n",
    "                                               name='acc_of_ones')\n",
    "        \n",
    "        accuracy = tf.metrics.accuracy(labels=psw_cutted, \n",
    "                                       predictions=prediction, \n",
    "                                       name='my_accuracy')\n",
    "\n",
    "        precision = tf.metrics.precision(labels=psw_cutted, \n",
    "                                         predictions=prediction, \n",
    "                                         name='my_precision')\n",
    "\n",
    "        tf.summary.scalar('my_acc', accuracy[1])\n",
    "        tf.summary.scalar('my_prec', precision[1])\n",
    "        tf.summary.scalar('my_acc_of_one', accuracy_of_ones[1])\n",
    "        \n",
    "        \n",
    "    # Loss\n",
    "    with tf.name_scope('Loss_prepare') as scope:\n",
    "        loss = tf.losses.mean_pairwise_squared_error(labels=psw_cutted, predictions=logits) # [!] model.info\n",
    "        if L2_ACTIVATED:\n",
    "            l2_regularizer = tf.contrib.layers.l2_regularizer(scale=L2_SCALE, scope='l2_regularization') \n",
    "            weights = tf.trainable_variables() \n",
    "            regularization_penalty = tf.contrib.layers.apply_regularization(l2_regularizer, weights)\n",
    "            regularized_loss = loss + regularization_penalty\n",
    "            loss = regularized_loss\n",
    "            \n",
    "            \n",
    "    #################\n",
    "    # DEBUG INSIGHTS\n",
    "    #################\n",
    "    \n",
    "    dict_debug = {}\n",
    "    dict_debug['Match encoded[0]'] = match_encoded[0]\n",
    "    dict_debug['Logits'] = logits\n",
    "    dict_debug['Prediction'] = prediction\n",
    "    dict_debug['Password'] = psw_encoded\n",
    "    dict_debug['Password_cutted'] = psw_cutted\n",
    "    dict_debug['Equality'] = equality\n",
    "    dict_debug['Accuracy_of_ones'] = ones_acc\n",
    "    dict_debug['Real_Accuracy'] = custom_accuracy\n",
    "    dict_debug['Psw_Pre_Predicted'] = psw_pre_predicted\n",
    "    dict_debug['Psw_Pre_Predicted_Padded_1'] = psw_pre_predicted_padded[:,:18]\n",
    "    dict_debug['Psw_Pre_Predicted_Padded_2'] = psw_pre_predicted_padded[:,18:]\n",
    "    \n",
    "    # Hooks\n",
    "    debug_hook = [tf.train.LoggingTensorHook(dict_debug, every_n_iter=30)] if DEBUG_HOOK else []     \n",
    "  \n",
    "\n",
    "        \n",
    "    #####################\n",
    "    # TRAIN & EVAL MODE\n",
    "    ####################\n",
    "    \n",
    "    # 2 - Evaluation mode\n",
    "    if mode == tf.estimator.ModeKeys.EVAL: \n",
    "        custom_metrics = {'my_acc':accuracy, 'my_prec':precision, 'my_acc_of_one':accuracy_of_ones}\n",
    "        return tf.estimator.EstimatorSpec(mode, \n",
    "                                          loss=loss,\n",
    "                                          eval_metric_ops=custom_metrics)\n",
    "    \n",
    "    # 3 - Train mode\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=ALPHA)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode,\n",
    "                                      loss=loss,\n",
    "                                      training_hooks = debug_hook,\n",
    "                                      train_op=train_op\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## 5. Run\n",
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##########\n",
    "# # RUN\n",
    "# ##########\n",
    "# def save_params(params, path):\n",
    "#     with open(path, 'w') as f:\n",
    "#         json.dump(params, f, indent=1, sort_keys=True)\n",
    "#         print('{} saved'.format(path))\n",
    "\n",
    "# save_params(model_params,\"temp_model.info\")\n",
    "\n",
    "# time_start = time.time()\n",
    "# my_train_and_evaluate(test_model_fn, input_fn, eval_fn, STEPS, model_params)\n",
    "# total_time = time.time() - time_start\n",
    "\n",
    "# time_consumed = str(datetime.timedelta(seconds=total_time))[:-7]\n",
    "# model_params['train_duration'] = time_consumed\n",
    "\n",
    "# save_params(model_params, MODEL_DIR_PATH+\"/model.info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "WIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Invoke What-If Tool for test data and the trained model {display-mode: \"form\"}\n",
    "\n",
    "num_datapoints = 2000  #@param {type: \"number\"}\n",
    "tool_height_in_px = 1000  #@param {type: \"number\"}\n",
    "\n",
    "from witwidget.notebook.visualization import WitConfigBuilder\n",
    "from witwidget.notebook.visualization import WitWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_NAME = ['Guess 1', 'Guess 2', 'Guess 3', 'Guess 4', 'Guess 5',\n",
    "          'Guess 6', 'Guess 7', 'Guess 8', 'Guess 9', 'Guess 10']\n",
    "\n",
    "TARGET_NAME = 'PASSWORD'\n",
    "\n",
    "features_and_labels = FEATURES_NAME + [TARGET_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the df load\n",
    "feature_type = {}\n",
    "cuts_type = {}\n",
    "feature_type[TARGET_NAME] = str\n",
    "for feature in FEATURES_NAME:\n",
    "    feature_type[feature] = str\n",
    "    cuts_type[feature] = int\n",
    "    \n",
    "path_df_train = \"../database/dbML/hopeful/JOINED_hopeful_2019-07-01_0.7_train.csv\"\n",
    "df_train = pd.read_csv(path_df_train, delimiter=',',encoding='utf-8', skip_blank_lines=True, dtype=feature_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a tf feature spec from the dataframe and columns specified.\n",
    "def create_feature_spec(df, columns=None):\n",
    "    feature_spec = {}\n",
    "    if columns == None:\n",
    "        columns = df.columns.values.tolist()\n",
    "    for f in columns:\n",
    "        if df[f].dtype is np.dtype(np.int64):\n",
    "            feature_spec[f] = tf.FixedLenFeature(shape=(), dtype=tf.int64)\n",
    "        elif df[f].dtype is np.dtype(np.float64):\n",
    "            feature_spec[f] = tf.FixedLenFeature(shape=(), dtype=tf.float32)\n",
    "        else:\n",
    "            feature_spec[f] = tf.FixedLenFeature(shape=(), dtype=tf.string)\n",
    "    return feature_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature spec for the classifier\n",
    "feature_spec = create_feature_spec(df_train, features_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a dataframe into a list of tf.Example protos.\n",
    "def df_to_examples(df, columns=None):\n",
    "    examples = []\n",
    "    if columns == None:\n",
    "        columns = df.columns.values.tolist()\n",
    "    for index, row in df.iterrows():\n",
    "        example = tf.train.Example()\n",
    "        for col in columns:\n",
    "            if df[col].dtype is np.dtype(np.int64):\n",
    "                example.features.feature[col].int64_list.value.append(int(row[col]))\n",
    "            elif df[col].dtype is np.dtype(np.float64):\n",
    "                example.features.feature[col].float_list.value.append(row[col])\n",
    "            elif row[col] == row[col]:\n",
    "                example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n",
    "        examples.append(example)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datapoints = 2000  \n",
    "tool_height_in_px = 1000  \n",
    "\n",
    "test_examples = df_to_examples(df_train[0:num_datapoints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0823 18:20:45.915928 139886312556352 estimator.py:201] Using config: {'_model_dir': '../networks/Trained/hopeful/model_dir_647_0/', '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_steps': 18961, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3977128f28>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = create_estimator(test_model_fn, input_fn, eval_fn, STEPS, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21858bf245a14487a7a29b03828987be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WitWidget(config={'model_type': 'classification', 'label_vocab': [], 'are_sequence_examples': False, 'inferencâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0823 18:20:54.355251 139886312556352 deprecation.py:323] From /mnt/c/Users/Simone Guardati/UbuntuWorkspace/envMM/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "I0823 18:20:54.425079 139886312556352 estimator.py:1111] Calling model_fn.\n",
      "I0823 18:20:54.425833 139886312556352 <ipython-input-13-2ac873cfbdee>:7] Params:{'_NETWORK_TYPE': 'BiLSTM_AttentionSystem', 'CSV_PATH_TRAIN': '../database/dbML/knuthFast/knuthFast_2019-07-30_0.9_75844_train.csv', 'CSV_PATH_EVAL': '../database/dbML/knuthFast/knuthFast_2019-07-30_0.9_8516_eval.csv', 'MODEL_DIR_PATH': '../networks/Trained/hopeful/model_dir_647_0/', 'EPOCHS': 10, 'ALPHA': 0.001, 'FW_FORGET_BIAS': 1, 'BW_FORGET_BIAS': 1, 'LSTM_SIZE': 256, 'NUM_EVALS': 10, 'BATCH_TRAIN': 4, 'BATCH_EVAL': 4, 'SHUFFLE_EVAL': True, 'EVAL_STEPS': None, 'MULTI_THREADING': True, 'INPUT_ENCODING': 'Peg: Hot encoding, Tips: One Hot Encoding', 'GOAL': 'goalReduced', 'ATTENTION_SIZE': 256, 'MAXOUT_SIZE': 256, 'DROP_REPRESENTATION': 0.3, 'GOAL_POS': 0, 'loss_fn': 'mean_pairwise_squared_error', 'L2_SCALE': 0.001}\n",
      "W0823 18:20:55.618594 139886312556352 deprecation.py:323] From /mnt/c/Users/Simone Guardati/UbuntuWorkspace/envMM/lib/python3.6/site-packages/tensorflow/python/ops/lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "W0823 18:20:55.714318 139886312556352 deprecation.py:323] From <ipython-input-11-eded0f3e6002>:39: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0823 18:20:57.004391 139886312556352 deprecation.py:323] From <ipython-input-13-2ac873cfbdee>:33: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0823 18:20:57.005520 139886312556352 deprecation.py:323] From <ipython-input-13-2ac873cfbdee>:39: static_bidirectional_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API\n",
      "W0823 18:20:57.006254 139886312556352 deprecation.py:323] From /mnt/c/Users/Simone Guardati/UbuntuWorkspace/envMM/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:1565: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "W0823 18:20:57.385150 139886312556352 deprecation.py:323] From <ipython-input-13-2ac873cfbdee>:59: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0823 18:20:57.388165 139886312556352 deprecation.py:506] From <ipython-input-12-957dda4a261f>:14: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W0823 18:20:57.390903 139886312556352 deprecation.py:323] From <ipython-input-13-2ac873cfbdee>:62: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "I0823 18:20:57.411034 139886312556352 estimator.py:1113] Done calling model_fn.\n",
      "I0823 18:20:57.497763 139886312556352 monitored_session.py:222] Graph was finalized.\n",
      "W0823 18:20:57.505675 139886312556352 deprecation.py:323] From /mnt/c/Users/Simone Guardati/UbuntuWorkspace/envMM/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0823 18:20:57.508901 139886312556352 saver.py:1270] Restoring parameters from ../networks/Trained/hopeful/model_dir_647_0/model.ckpt-227010\n",
      "I0823 18:20:57.661480 139886312556352 session_manager.py:491] Running local_init_op.\n",
      "I0823 18:20:57.700612 139886312556352 session_manager.py:493] Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "# Setup the tool with the test examples and the trained classifier\n",
    "config_builder = WitConfigBuilder(test_examples).set_estimator_and_feature_spec(classifier, feature_spec)\n",
    "\n",
    "WitWidget(config_builder, height=tool_height_in_px)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
