{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database manager\n",
    "1. Join multiple csv\n",
    "2. Remove the password from the match\n",
    "2. Shuffle the csv\n",
    "3. Split in _train_ and _eval_ databases ready for ML\n",
    "\n",
    "## Params\n",
    "- **PLAYER_ALGORITHM**\n",
    "    - The database that use for the process\n",
    "- **ONLY_TRAIN:** \n",
    "    - if _True_ = the system only join all data inside \"dbPlayers/_player_/chest/*.csv\"\n",
    "    - if _False_ = the system join all data inside \"dbPlayers/_player_/chest/*.csv\", then remove password, split in train and eval and save everything inside \"dbML/_player_/*_train.csv\" and \"dbML/_player_/*_wval.csv\"\n",
    "- **TRAIN_QUOTE:**\n",
    "    - If _ONLY_TRAIN=False_ this parameter specify the quote for split the db in Train/Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAYER_ALGORITHM = 'hopeful' # [knuth, knuthFast, hopeful]\n",
    "ONLY_JOIN = False\n",
    "TRAIN_QUOTE = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "**Environment prepare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT_PATH(prefix): ./dbML/hopeful/hopeful_2019-10-05\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "DATE = datetime.today().strftime('%Y-%m-%d')\n",
    "os.putenv(\"PLAYER_ALGORITHM\", PLAYER_ALGORITHM)\n",
    "PATHS_CSV_TO_JOIN = !find ./dbPlayers/${\"PLAYER_ALGORITHM\"}/chest/ | grep csv | grep -v _cuts\n",
    "OUT_FOLDER = 'dbPlayers' if ONLY_JOIN else 'dbML'\n",
    "OUTPUT_PATH = './{out_folder}/{player}/{player}_{date}'.format(out_folder=OUT_FOLDER, \n",
    "                                                               player=PLAYER_ALGORITHM, \n",
    "                                                               date=DATE)\n",
    "print('OUTPUT_PATH(prefix):',OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "## Data pipeline\n",
    "### 1. Load and remove the psw from the match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_last_guess(psw):\n",
    "    if psw[-2] == '4':\n",
    "        return '<pad>'\n",
    "    else:\n",
    "        return psw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataframe len:1036800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Guess 1</th>\n",
       "      <th>Guess 2</th>\n",
       "      <th>Guess 3</th>\n",
       "      <th>Guess 4</th>\n",
       "      <th>Guess 5</th>\n",
       "      <th>Guess 6</th>\n",
       "      <th>Guess 7</th>\n",
       "      <th>Guess 8</th>\n",
       "      <th>Guess 9</th>\n",
       "      <th>Guess 10</th>\n",
       "      <th>PASSWORD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ADDB10</td>\n",
       "      <td>ACFC10</td>\n",
       "      <td>ECBB00</td>\n",
       "      <td>FDFF00</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>AAAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BEAD11</td>\n",
       "      <td>FEDC00</td>\n",
       "      <td>ABAA22</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>AAAB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Guess 1 Guess 2 Guess 3 Guess 4 Guess 5 Guess 6 Guess 7 Guess 8 Guess 9  \\\n",
       "0  ADDB10  ACFC10  ECBB00  FDFF00   <pad>   <pad>   <pad>   <pad>   <pad>   \n",
       "1  BEAD11  FEDC00  ABAA22   <pad>   <pad>   <pad>   <pad>   <pad>   <pad>   \n",
       "\n",
       "  Guess 10 PASSWORD  \n",
       "0    <pad>     AAAA  \n",
       "1    <pad>     AAAB  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Params\n",
    "df_list = []\n",
    "features_name = ['Guess 1', 'Guess 2', 'Guess 3', 'Guess 4', 'Guess 5',\n",
    "                  'Guess 6', 'Guess 7', 'Guess 8', 'Guess 9', 'Guess 10']\n",
    "target_name = 'PASSWORD'\n",
    "\n",
    "# Optimize the df load\n",
    "feature_type = {}\n",
    "feature_type[target_name] = str\n",
    "for feature in features_name:\n",
    "    feature_type[feature] = str\n",
    "\n",
    "# Load the db\n",
    "for path in PATHS_CSV_TO_JOIN:\n",
    "    df = pd.read_csv(path, delimiter=',',encoding='utf-8', skip_blank_lines=True, dtype=feature_type)\n",
    "    if not ONLY_JOIN:\n",
    "        for feature in df.keys():\n",
    "            df[feature] = df[feature].map(replace_last_guess)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Join the csv\n",
    "df_total = pd.concat(df_list, sort = False)\n",
    "print('New dataframe len:{}'.format(len(df_total)))\n",
    "df_total.iloc[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Shuffle and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train size:\t829843\n",
      "[INFO] Eval size:\t206957\n"
     ]
    }
   ],
   "source": [
    "# Shuffle for train - Eval\n",
    "if not ONLY_JOIN:\n",
    "    df_total = df_total.sample(frac=1, random_state=42)\n",
    "    msk = np.random.rand(len(df_total)) < TRAIN_QUOTE\n",
    "    df_train = df_total[msk]\n",
    "    df_eval = df_total[~msk]\n",
    "    print('[INFO] Train size:\\t{}\\n[INFO] Eval size:\\t{}'.format(len(df_train),len(df_eval)))\n",
    "    df_train.iloc[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and eval saved\n"
     ]
    }
   ],
   "source": [
    "if ONLY_JOIN:   \n",
    "    # Match history\n",
    "    with open(OUTPUT_PATH+\".csv\", 'w') as f:\n",
    "        df_total.to_csv(f, sep=',', encoding='utf-8',index=False, header=True)\n",
    "    print('Joined file saved')\n",
    "    \n",
    "    # Cuts histories\n",
    "    df_list_cut = []\n",
    "    for path in PATHS_CSV_TO_JOIN:\n",
    "        path = path[:-4] + '_cuts.csv'\n",
    "        df_cut = pd.read_csv(path, delimiter=',',encoding='utf-8', skip_blank_lines=True)\n",
    "        df_cut[features_name] = df_cut[features_name].apply(pd.to_numeric, downcast='integer')\n",
    "        df_list_cut.append(df_cut)\n",
    "    df_total_cuts = pd.concat(df_list_cut, sort = False)\n",
    "    \n",
    "    with open(OUTPUT_PATH+\"_cuts.csv\", 'w') as f:\n",
    "        df_total_cuts.to_csv(f, sep=',', encoding='utf-8',index=False, header=True)\n",
    "    print('Cuts file saved')\n",
    "    \n",
    "\n",
    "else:\n",
    "    # Train ML database\n",
    "    with open(OUTPUT_PATH+\"_{}_{}_train.csv\".format(TRAIN_QUOTE, len(df_train)), 'w') as f:\n",
    "        df_train.to_csv(f, sep=',', encoding='utf-8',index=False, header=True)\n",
    "    \n",
    "    # Eval ML database\n",
    "    with open(OUTPUT_PATH+\"_{}_{}_eval.csv\".format(TRAIN_QUOTE, len(df_eval)), 'w') as f:\n",
    "        df_eval.to_csv(f, sep=',', encoding='utf-8',index=False, header=True)\n",
    "\n",
    "    print('Train and eval saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
